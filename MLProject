name: bert-classification

conda_env: conda.yaml

entry_points:
  main:
    parameters:
      problem_name: {type: str, default: "endoscopy_icd_30"}
      max_seq_length: {type: int, default: 4000}
      n_epoch: {type int, default: 50}
      patience: {type: int, default: 5}
      batch_size: {type: int, default: 8}
      optimiser: {type: str, default: "adamw"}
      lr: {type: float, default: 0.001}
      dropout: {type: float, default: 0.3}
      level_projection_size: {type: int, default: 128}
      main_metric: {type: str, default: "micro_f1"}
      mode: {type: str, default: "static"}
      embedding_mode: {type: str, default: "word2vec"}
      embedding_file: {type: str, default: "data/embeddings/word2vec_sg0_100.model"}
      attention_mode: {type: str, default: "label"}
      joint_mode: {type: str, default: "hierarchical"}
      d_a: {type: int, default: 512}

    command: |
          python3 -m src.run \
            --problem_name {problem_name} \
            --max_seq_length {max_seq_length} \
            --n_epoch {n_epoch} \
            --patience {patience} \
            --batch_size {batch_size} \
            --optimiser {optimiser} \
            --lr {lr} \
            --dropout {dropout} \
            --level_projection_size {level_projection_size} \
            --main_metric {main_metric} \
            --mode {mode} \
            --embedding_mode {embedding_mode} \
            --embedding_file {embedding_file} \
            --attention_mode {attention_mode} \
            --joint_mode {joint_mode} \
            --d_a {d_a} \
            CNN 